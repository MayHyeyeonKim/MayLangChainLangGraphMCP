{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97f06add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.13.2\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b76fdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72523213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When choosing a pitcher for latte art, the spout design is an important factor to consider. A sharper or more tapered spout generally provides better control over the milk flow, which is essential for creating detailed and intricate patterns. This is because a sharper spout allows you to more precisely control the stream of milk, making it easier to draw fine lines and complex designs.\n",
      "\n",
      "While rounded spouts can be used for latte art, they are often better suited for simpler designs, as they don't provide the same level of control. If your goal is to improve your latte art skills and create more intricate patterns, you might want to try a pitcher with a sharper spout.\n",
      "\n",
      "Additionally, other factors such as the size and shape of the pitcher, the handle, and your personal comfort with it also play roles in your success with latte art. Many baristas find that experimenting with different pitchers helps them find the one that best suits their style and technique.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "query = \"Which pitcher is better for latte art? Mine has a rounded spout, but should the spout be sharper?\"\n",
    "\n",
    "llm = ChatOpenAI(model= 'gpt-4o')\n",
    "\n",
    "result = llm.invoke(query)\n",
    "\n",
    "print(result.content)\n",
    "\n",
    "save_dir = \"results\"\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "filename = f\"{datetime.now().isoformat()}-result.md\"\n",
    "save_path = os.path.join(save_dir, filename)\n",
    "\n",
    "# save\n",
    "with open(save_path, \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"**Questions** \\n {query}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"**Answer** \\n {result.content}\\n\\n\")\n",
    "\n",
    "# 이게 랭체인으로 했던 방법임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e41178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랭그래프\n",
    "# State, Node, Edge, Conditional Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83a111d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langgraph\n",
      "Version: 0.2.60\n",
      "Summary: Building stateful, multi-actor applications with LLMs\n",
      "Home-page: https://www.github.com/langchain-ai/langgraph\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /Users/hyeyeonkim/MayLangChainLangGraphMCP/.venv/lib/python3.13/site-packages\n",
      "Requires: langchain-core, langgraph-checkpoint, langgraph-sdk\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef5fcfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: list[Annotated[AnyMessage, add_messages]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95833722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph builder\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "graph_builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0080181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node\n",
    "\n",
    "def generate(state:AgentState) -> AgentState:\n",
    "    messages = state['messages']\n",
    "    ai_message = llm.invoke(messages)\n",
    "    return {'messages' : [ai_message]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7665057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11eb723c0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, END\n",
    "# graph_builder.add_node('generate', generate) # <langgraph.graph.state.StateGraph at 0x11eb723c0>\n",
    "graph_builder.add_edge(START, 'generate')\n",
    "graph_builder.add_edge('generate', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4874456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1fe45a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mermaid\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadc555d",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Invalid 'messages': empty array. Expected an array with minimum length 1, but got an empty array instead.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'empty_array'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HumanMessage\n\u001b[1;32m      3\u001b[0m initial_state \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m: []}\n\u001b[0;32m----> 4\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MayLangChainLangGraphMCP/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:1936\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1934\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1935\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1936\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1944\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1945\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1946\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/MayLangChainLangGraphMCP/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:1656\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1650\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1652\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1656\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1657\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1658\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1659\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1660\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1661\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   1663\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/MayLangChainLangGraphMCP/.venv/lib/python3.13/site-packages/langgraph/pregel/runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/MayLangChainLangGraphMCP/.venv/lib/python3.13/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/MayLangChainLangGraphMCP/.venv/lib/python3.13/site-packages/langgraph/utils/runnable.py:408\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    405\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    406\u001b[0m )\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/MayLangChainLangGraphMCP/.venv/lib/python3.13/site-packages/langgraph/utils/runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(state:AgentState) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AgentState:\n\u001b[1;32m      4\u001b[0m     messages \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m     ai_message \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m : [ai_message]}\n",
      "File \u001b[0;32m~/MayLangChainLangGraphMCP/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:383\u001b[0m, in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    369\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    379\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n\u001b[1;32m    381\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mainvoke\u001b[39m(\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m    385\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    387\u001b[0m     stop: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    389\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    390\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    391\u001b[0m     llm_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate_prompt(\n\u001b[1;32m    392\u001b[0m         [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[1;32m    393\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    400\u001b[0m     )\n",
      "File \u001b[0;32m~/MayLangChainLangGraphMCP/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1006\u001b[0m, in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mid \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1004\u001b[0m             chunk\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_manager\u001b[38;5;241m.\u001b[39mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1005\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_new_token(\n\u001b[0;32m-> 1006\u001b[0m             cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m, chunk\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent), chunk\u001b[38;5;241m=\u001b[39mchunk\n\u001b[1;32m   1007\u001b[0m         )\n\u001b[1;32m   1008\u001b[0m     chunks\u001b[38;5;241m.\u001b[39mappend(chunk)\n\u001b[1;32m   1009\u001b[0m result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n",
      "File \u001b[0;32m~/MayLangChainLangGraphMCP/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:825\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magenerate\u001b[39m(\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    799\u001b[0m     messages: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[BaseMessage]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    808\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    809\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Asynchronously pass a sequence of prompts to a model and return generations.\u001b[39;00m\n\u001b[1;32m    810\u001b[0m \n\u001b[1;32m    811\u001b[0m \u001b[38;5;124;03m    This method should make use of batched calls for models that expose a batched\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;124;03m    API.\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \n\u001b[1;32m    814\u001b[0m \u001b[38;5;124;03m    Use this method when you want to:\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;124;03m        1. take advantage of batched calls,\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;124;03m        2. need more output from the model than just the top generated value,\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;124;03m        3. are building chains that are agnostic to the underlying language model\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;124;03m            type (e.g., pure text completion models vs chat models).\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \n\u001b[1;32m    820\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;124;03m        messages: List of list of messages.\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;124;03m        stop: Stop words to use when generating. Model output is cut off at the\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;124;03m            first occurrence of any of these substrings.\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;124;03m        callbacks: Callbacks to pass through. Used for executing additional\u001b[39;00m\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;124;03m            functionality, such as logging or streaming, throughout generation.\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;124;03m        tags: The tags to apply.\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;124;03m        metadata: The metadata to apply.\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;124;03m        run_name: The name of the run.\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;124;03m        run_id: The ID of the run.\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;124;03m        **kwargs: Arbitrary additional keyword arguments. These are usually passed\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;124;03m            to the model provider API call.\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \n\u001b[1;32m    833\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;124;03m        An LLMResult, which contains a list of candidate Generations for each input\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;124;03m            prompt and additional model provider-specific output.\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    837\u001b[0m     ls_structured_output_format \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\n\u001b[1;32m    838\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mls_structured_output_format\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    839\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstructured_output_format\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    840\u001b[0m     ls_structured_output_format_dict \u001b[38;5;241m=\u001b[39m _format_ls_structured_output(\n\u001b[1;32m    841\u001b[0m         ls_structured_output_format\n\u001b[1;32m    842\u001b[0m     )\n",
      "File \u001b[0;32m~/MayLangChainLangGraphMCP/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1072\u001b[0m, in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream(\n\u001b[1;32m   1067\u001b[0m     async_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1068\u001b[0m     run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m   1069\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1070\u001b[0m ):\n\u001b[1;32m   1071\u001b[0m     chunks: \u001b[38;5;28mlist\u001b[39m[ChatGenerationChunk] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1072\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_astream(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1073\u001b[0m         chunk\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mresponse_metadata \u001b[38;5;241m=\u001b[39m _gen_info_and_msg_metadata(chunk)\n\u001b[1;32m   1074\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_manager:\n",
      "File \u001b[0;32m~/MayLangChainLangGraphMCP/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1177\u001b[0m, in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tool_choice\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mbind(tools\u001b[38;5;241m=\u001b[39mformatted_tools, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwith_structured_output\u001b[39m(\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1172\u001b[0m     schema: Optional[_DictOrPydanticClass] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   1174\u001b[0m     method: Literal[\n\u001b[1;32m   1175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_calling\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson_schema\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1176\u001b[0m     ] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_calling\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m-> 1177\u001b[0m     include_raw: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1178\u001b[0m     strict: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1179\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Runnable[LanguageModelInput, _DictOrPydantic]:\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Model wrapper that returns outputs formatted to match the given schema.\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m \n\u001b[1;32m   1183\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;124;03m            # }\u001b[39;00m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m   1452\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m~/MayLangChainLangGraphMCP/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py:287\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m _V \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_V\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;129m@overload\u001b[39m\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstrip_not_given\u001b[39m(obj: \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;129m@overload\u001b[39m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstrip_not_given\u001b[39m(obj: Mapping[_K, _V \u001b[38;5;241m|\u001b[39m NotGiven]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[_K, _V]: \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n",
      "File \u001b[0;32m~/MayLangChainLangGraphMCP/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:1150\u001b[0m, in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n",
      "File \u001b[0;32m~/MayLangChainLangGraphMCP/.venv/lib/python3.13/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;129m@overload\u001b[39m\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     stream: Literal[\u001b[38;5;28;01mTrue\u001b[39;00m],\n\u001b[1;32m   1250\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT],\n\u001b[1;32m   1251\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _StreamT: \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;129m@overload\u001b[39m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1256\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   1258\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m-> 1259\u001b[0m     body: Body \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1260\u001b[0m     options: RequestOptions \u001b[38;5;241m=\u001b[39m {},\n\u001b[1;32m   1261\u001b[0m     files: RequestFiles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1262\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m   1263\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1264\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT: \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n",
      "File \u001b[0;32m~/MayLangChainLangGraphMCP/.venv/lib/python3.13/site-packages/openai/_base_client.py:1047\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1045\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m-> 1047\u001b[0m         input_options,\n\u001b[1;32m   1048\u001b[0m         cast_to,\n\u001b[1;32m   1049\u001b[0m         retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1050\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m   1051\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1052\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1053\u001b[0m     )\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Invalid 'messages': empty array. Expected an array with minimum length 1, but got an empty array instead.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'empty_array'}}",
      "\u001b[0mDuring task with name 'generate' and id '689e30f8-b9ec-9cc9-92be-96e8a7a2277f'"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "initial_state = {'messages': [HumanMessage(content=query)]}\n",
    "graph.invoke(initial_state)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
